# -*- coding: utf-8 -*-
"""Multiclass_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rksvjTvNKB5SOFkakaoz2kn5rvpzu2Qo

Dataset : CNN News Articles from 2011 to 2022

link dataset : https://www.kaggle.com/datasets/hadasu92/cnn-articles-after-basic-cleaning
"""

#mount google drive
from google.colab import drive
drive.mount('/content/drive')

#mengekstrak file dari google drive
!unzip "/content/drive/MyDrive/machine learning/archive.zip" -d "/content/drive/MyDrive/machine learning/cnn"

#mengubah dataset menjadi dataframe
import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/machine learning/cnn/CNN_Articels_clean/CNN_Articels_clean.csv")
df.head()

df.info()

#hapus beberapa kolom yang tidak diperlukan
df = df.drop(columns=['Index', 'Author', 'Date published', 'Section', 'Url', 'Keywords', 'Second headline', 'Article text'])

#cek kembali dataframe
df.head(5)

#melakukan one-hot-encoding pada label
Category = pd.get_dummies(df.Category)
df_baru = pd.concat([df, Category], axis=1)
df_baru = df_baru.drop(columns='Category')
df_baru

#mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array
deskripsi = df_baru['Headline'].values + '' + df_baru['Description'].values
label = df_baru[['business', 'entertainment', 'health', 'news', 'politics', 'sport']].values

#bagi data untuk training dan data untuk testing
from sklearn.model_selection import train_test_split
deskripsi_latih, deskripsi_test, label_latih, label_test = train_test_split(deskripsi, label, test_size=0.2)

#tokenizer dan konversi menjadi sequence
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(deskripsi_latih) 
tokenizer.fit_on_texts(deskripsi_test)
 
sekuens_latih = tokenizer.texts_to_sequences(deskripsi_latih)
sekuens_test = tokenizer.texts_to_sequences(deskripsi_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(6, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

#callback jika akurasi dan val akurasi diatas 90%
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nNilai akurasi dan validasi telah mencapai 90%!")
      self.model.stop_training = True
callbacks = myCallback()

#melatih model
num_epochs = 30
history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

#membuat plot diagram akurasi
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Keakurasian model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['latih', 'test'], loc='upper left')
plt.show()

#membuat plot diagram loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('loss model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['latih', 'test'], loc='upper left')
plt.show()